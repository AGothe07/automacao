{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7506539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programacao\\automacao\\Llama\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def4be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "llm = Groq(model=\"llama3-70b-8192\", \n",
    "           api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12012ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_imposto_renda(rendimento:float) -> str:\n",
    "    \"\"\"\n",
    "    calcular o imposto de renda com base no rendimento atual.\n",
    "    Args:\n",
    "        rendimento(float) : Redndimetno anual do individuo.\n",
    "\n",
    "    Returns:\n",
    "        str: o valor do imposto devido com base no rendimento\n",
    "    \"\"\"\n",
    "    if rendimento <=2000:\n",
    "        return \"Você esta isento de pagar imposto de renda\"\n",
    "    elif 2000 < rendimento <= 5000:\n",
    "        imposto = (rendimento - 2000) * 0.10\n",
    "        return f\"O imposto devido é de R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}\"\n",
    "    elif 5000 < rendimento <= 10000: \n",
    "        imposto = (rendimento - 5000) * 0.15 + 300\n",
    "        return f\"O imposto devido é de R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}\"\n",
    "    else:\n",
    "        imposto = (rendimento - 10000) * 0.20 + 1050\n",
    "        return f\"O imposto devido é de R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b270b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664e4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferramenta_imposto_renda = FunctionTool.from_defaults(\n",
    "    fn=calcular_imposto_renda,\n",
    "    name= \"calcular imposto de Renda\",\n",
    "    description=(\n",
    "        \"calcula o imposto de renda com base no rendimento atual\"\n",
    "        \"Argumento: redimento (float)\"\n",
    "        \"retorna o valor do imposto devido de acordo com faixa de rendimento\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91238119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651f76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker_imposto = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[ferramenta_imposto_renda],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbd8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65be845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_11324\\1872460396.py:1: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  agent_imposto = AgentRunner(agent_worker_imposto)\n"
     ]
    }
   ],
   "source": [
    "agent_imposto = AgentRunner(agent_worker_imposto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "881360a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: \n",
      "Qual é o imposto de renda devido de uma pessoa com rendimento anual de 7500 reais?\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: calcular imposto de Renda with args: {\"rendimento\": 7500}\n",
      "=== Function Output ===\n",
      "O imposto devido é de R$ 675.00, base em um rendimento de R$ 7500.00\n",
      "=== LLM Response ===\n",
      "O imposto devido é de R$ 675.00, base em um rendimento de R$ 7500.00\n"
     ]
    }
   ],
   "source": [
    "response = agent_imposto.chat(\"\"\"\n",
    "Qual é o imposto de renda devido de uma pessoa com rendimento anual de 7500 reais?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab1c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "def consulta_artigos(titulo: str) -> str:\n",
    "    \"\"\"Consulta os artigos na base de dados ArXiv e retorna os resultados formatados\"\"\"\n",
    "    busca = arxiv.Search(\n",
    "        query = titulo,\n",
    "        max_results = 5,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    resultados = [\n",
    "        f\"Título: {artigo.title} \\n\"\n",
    "        f\"Categoria: {artigo.primary_category} \\n\"\n",
    "        f\"Link: {artigo.entry_id} \\n\"\n",
    "        for artigo in busca.results()\n",
    "    ]\n",
    "\n",
    "    return \"\\n\\n\".join(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45e36266",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta_artigos_tool = FunctionTool.from_defaults(fn=consulta_artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb11480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [ferramenta_imposto_renda, consulta_artigos_tool],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78fa1df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Me retorne artigos sobre langChain na educação\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_11324\\3122400025.py:1: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  agent = AgentRunner(agent_worker)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"langChain educa\\u00e7\\u00e3o\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_11324\\3843034253.py:15: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for artigo in busca.results()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application? \n",
      "Categoria: cs.CR \n",
      "Link: http://arxiv.org/abs/2308.01990v4 \n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations \n",
      "Categoria: cs.CL \n",
      "Link: http://arxiv.org/abs/2310.05421v1 \n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain \n",
      "Categoria: cs.CL \n",
      "Link: http://arxiv.org/abs/2406.18122v1 \n",
      "\n",
      "\n",
      "Título: Breast Ultrasound Report Generation using LangChain \n",
      "Categoria: eess.IV \n",
      "Link: http://arxiv.org/abs/2312.03013v1 \n",
      "\n",
      "\n",
      "Título: Revolutionizing Mental Health Care through LangChain: A Journey with a Large Language Model \n",
      "Categoria: cs.HC \n",
      "Link: http://arxiv.org/abs/2403.05568v1 \n",
      "\n",
      "=== LLM Response ===\n",
      "It seems that the tool call yielded a list of research papers related to LangChain, but not specifically focused on education. However, I can try to provide a summary or insights based on the titles and categories of the papers.\n",
      "\n",
      "From the titles, it appears that LangChain is being explored in various domains, including web application security, customer service, language models, medical report generation, and mental health care. While these papers may not directly address LangChain in education, they could potentially have implications for educational applications or inspire new ideas for using LangChain in educational contexts.\n",
      "\n",
      "If you'd like, I can try to call another tool to explore LangChain's potential in education or provide more general information on the topic. Alternatively, I can respond directly to provide more insights or discuss the possibilities of LangChain in education.\n"
     ]
    }
   ],
   "source": [
    "agent = AgentRunner(agent_worker)\n",
    "response= agent.chat(\"Me retorne artigos sobre langChain na educação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c435bf",
   "metadata": {},
   "source": [
    "### Usando o Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652760fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_= load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e1d7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_key = os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "382e3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "\n",
    "tavily_tool = TavilyToolSpec(\n",
    "    api_key=tavily_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49d86ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n"
     ]
    }
   ],
   "source": [
    "tavily_tool_list = tavily_tool.to_tool_list()\n",
    "for tool in tavily_tool_list:\n",
    "    print(tool.metadata.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3fbc94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='885e4985-0b28-46da-b602-cd895707f530', embedding=None, metadata={'url': 'https://python.langchain.com/docs/introduction/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain simplifies every stage of the LLM application lifecycle: [...] Architecture\\u200b\\n-----------------------------------------------------------------------------------------------------------\\n\\nThe LangChain framework consists of multiple open-source libraries. Read more in the Architecture page. [...] Retrieval\\n       Retrievers\\n       Runnable interface\\n       Streaming\\n       Structured outputs\\n       Testing\\n       String-in, string-out llms\\n       Text splitters\\n       Tokens\\n       Tool calling\\n       Tools\\n       Tracing\\n       Vector stores\\n       Why LangChain?', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='781936a2-41d1-4a9e-a719-2b051a9c702e', embedding=None, metadata={'url': 'https://blog.dsacademy.com.br/langgraph-para-construcao-de-agentes-de-ia-arquitetura-orquestracao-e-casos-de-uso/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain (agentes padrão): O LangChain puro permite criar agentes através de chains ou usando o padrão ReAct (razão e agir) para escolher ferramentas. No entanto, esses agentes tendem a ser sequenciais e sem memória persistente – cada interação é tratada isoladamente, apoiando-se apenas no contexto imediato. Isso funciona bem para chatbots simples ou geração de texto linear, mas torna-se limitante para workflows complexos de múltiplos passos. O LangGraph, por outro lado, foi concebido [...] Concebido pelos criadores do LangChain, o LangGraph nasceu para suprir uma lacuna: enquanto o LangChain oferece interfaces simples para montar sequências de etapas com LLMs, faltava um meio fácil de introduzir ciclos nessas sequências. Agentes sofisticados muitas vezes precisam “pensar” em loop, refinando buscas ou tomando ações repetidas até atingir um objetivo. [...] Sendo parte do ecossistema LangChain, o LangGraph é altamente compatível com outras bibliotecas e ferramentas de IA suportadas pelo LangChain. Ele pode integrar qualquer modelo de linguagem ou provedor disponível no LangChain (OpenAI, modelos open-source via Hugging Face, Azure, etc.), assim como ferramentas externas (APIs, bancos de dados, motores de busca) definidos como ferramentas do LangChain. Em outras palavras, um nó no grafo do LangGraph pode ser um modelo da OpenAI ou um chamador de', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b26f33b3-0d8b-4fa4-ae6c-1286e56be88f', embedding=None, metadata={'url': 'https://academy.langchain.com/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='© Copyright LangChain Academy 2025 [...] Ready to start shipping reliable GenAI apps faster?\\n---------------------------------------------------\\n\\nGet started with LangChain, LangSmith, and LangGraph to enhance your LLM app development, from prototype to production.\\n\\nContact Sales\\n\\nBring LangChain Academy to Your Company\\n---------------------------------------\\n\\nNominate your company to receive a LangChain Academy training, \\n\\navailable both in-person at your office or remotely, at no cost.\\n\\nLearn More [...] LangChain Academy\\n\\n===============\\n\\n[](\\n\\nDocs\\n\\nPython\\n\\nLangChainLangSmithLangGraph\\n\\nJavaScript\\n\\nLangChainLangSmithLangGraph\\n\\nCommunityLangSmithAll Courses\\n\\nSign In\\n\\nRegister\\n\\nLangChain Academy\\n-----------------\\n\\nLevel up with LangChain Academy\\n-------------------------------\\n\\nDive into self-paced, comprehensive courses designed to help you build relevant skills and knowledge to succeed with LangChain products.\\n\\nWatch Intro Video\\n\\nOur Courses\\n-----------', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.search(\"Me retorne artigos cientificos sobre LangChain\", max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b92cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "\n",
    "tavily_tool_function = FunctionTool.from_defaults(\n",
    "    fn=tavily_tool.search,\n",
    "    name=\"Travily Search\",\n",
    "    description= \"Busca artigos com Tavily sobre um determinado tópico\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8b50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[tavily_tool_function],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls= False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed2a9e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_11324\\2541408032.py:1: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  agent = AgentRunner(agent_worker)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: me retorne artigos sobre llm e LangChain\n",
      "=== Calling Function ===\n",
      "Calling function: Travily Search with args: {\"max_results\": 6, \"query\": \"LLM and LangChain\"}\n",
      "=== Function Output ===\n",
      "[Document(id_='9803f7fb-eec3-42c3-9dc1-cd3015b5b5b1', embedding=None, metadata={'url': 'https://aws.amazon.com/what-is/langchain/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain is an open source framework for building applications based on large language models (LLMs). LLMs are large deep-learning models pre-trained on large amounts of data that can generate responses to user queries—for example, answering questions or creating images from text-based prompts. LangChain provides tools and abstractions to improve the customization, accuracy, and relevancy of the information the models generate. For example, developers can use LangChain components to build new [...] With LangChain, organizations can repurpose LLMs for domain-specific applications without retraining or fine-tuning. Development teams can build complex applications referencing proprietary information to augment model responses. For example, you can use LangChain to build applications that read data from stored internal documents and summarize them into conversational responses. You can create a Retrieval Augmented Generation (RAG) workflow that introduces new information to the language model [...] prompt chains or customize existing templates. LangChain also includes components that allow LLMs to access new data sets without retraining.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='033bf089-3ae0-4645-af25-79902deec416', embedding=None, metadata={'url': 'https://www.langchain.com/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# One interface, integrate any LLM.\\n\\nLangChain is the open, composable framework that provides a standard interface for every model, tool, and database â\\x80\\x93 so you can build LLM apps that adapt as fast as the ecosystem evolves.\\n\\n## Why use LangChain?\\n\\n## Composable by design\\n\\nLangChainâ\\x80\\x99s standard interface lets you experiment with different providers, tools, and databases â\\x80\\x93 creating DevEx parity when gaps exist.\\n\\n## Real-time data augmentation [...] LangChain is designed for connecting LLMs to data sources with minimal setup. LangGraph is our controllable agent orchestration framework, with out-of-the-box state management and human-in-the-loop capabilities. Use LangChain when you need fast integration and experimentation; use LangGraph when you need to build agents that can reliably handle complex tasks. [...] There are many different use cases for LangChain. Some common ones that we see include: chatbots and conversational interfaces, document Q&A and knowledge retrieval systems, and data extraction. LangChain excels when you need to connect LLMs to external data sources, APIs, or toolsâ\\x80\\x93 anywhere you need maximum integration flexibility.\\n\\nLangChain provides a standard interface for connecting models, tools, and data, then integrates seamlessly with any of the Lang- family products.Â\\n\\nâ\\x80\\x8d', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='eaaac182-cdd3-4166-b114-db42ddf57dd0', embedding=None, metadata={'url': 'https://medium.com/@bijit211987/llm-powered-applications-building-with-langchain-cad4032d733c'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain provides an OpenAI Codex-based Python framework that makes working with LLMs simple and productive.\\n\\nWith LangChain you can:\\n\\nIt offers a clean Python API for leveraging LLMs without dealing with external APIs and infrastructure complexity.\\n\\nLangChain enables building a wide range of intelligent applications powered by LLMs including:\\n\\nThe remainder of this guide provides a deep dive into LangChain’s architecture and usage through concrete examples building LLM-enhanced applications. [...] By providing a code-first approach, LangChain opens the door to tightly integrating LLMs with custom logic and data flows tailored to specialized domains. As LLMs continue their rapid advancements, LangChain allows builders at any skill level to leverage these models for real-world impact.\\n\\n--\\n\\n--\\n\\nBijit Ghosh\\nBijit Ghosh\\n\\n## Written by Bijit Ghosh\\n\\nCTO | Senior Engineering Leader focused on Cloud Native | AI/ML | DevSecOps\\n\\n## No responses yet\\n\\nHelp\\n\\nStatus\\n\\nAbout\\n\\nCareers\\n\\nPress\\n\\nBlog [...] LangChain offers a robust framework for seamlessly leveraging large language models to build cutting-edge AI applications. In this blog post, we will use LangChain to add LLM-powered natural language generation, search, analytics, and automation to applications ranging from chatbots to semantic code search.\\n\\n# Introduction to Large Language Models', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='43a2767c-0308-4df8-98ed-a6a42656a3c7', embedding=None, metadata={'url': 'https://www.ibm.com/think/topics/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# What is LangChain?\\n\\n## Authors\\n\\nSenior Writer, AI Models\\n\\nIBM\\n\\nEditorial Lead, AI Models\\n\\n## What is LangChain?\\n\\nLangChain is an open source orchestration framework for application development using large language models (LLMs). Available in both Python- and Javascript-based libraries, LangChain’s tools and APIs simplify the process of building LLM-driven applications like chatbots and AI agents. [...] LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows. LangChain’s module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code. This modular environment also allows for programs that use multiple LLMs: for example, an application that [...] ### Importing language models\\n\\nNearly any LLM can be used in LangChain. Importing language models into LangChain is easy, provided you have an API key. The LLM class is designed to provide a standard interface for all models.\\n\\nMost LLM providers will require you to create an account in order to receive an API key. Some of these APIs—particularly those for proprietary closed-source models, like those offered by OpenAI or Anthropic—may have associated costs.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='15c519f2-ed6d-4b01-9ef2-85a3147f2d88', embedding=None, metadata={'url': 'https://python.langchain.com/docs/introduction/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='🦜️🔗 LangChain\\n🦜️🔗 LangChain\\nOpen on GitHub\\n\\n# Introduction\\n\\nLangChain is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDiagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.\\nDiagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='e7f86e0d-5356-49d8-984b-6243e122b8f1', embedding=None, metadata={'url': 'https://github.com/langchain-ai/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain is a framework for building LLM-powered applications. It helps you chain\\ntogether interoperable components and third-party integrations to simplify AI\\napplication development — all while future-proofing decisions as the underlying\\ntechnology evolves.\\n\\n```\\npip install -U langchain\\n```\\n\\nTo learn more about LangChain, check out\\nthe docs. If you’re looking for more\\nadvanced customization or agent orchestration, check out\\nLangGraph, our framework for building\\ncontrollable agent workflows. [...] ## Why use LangChain?\\n\\nLangChain helps developers build applications powered by LLMs through a standard\\ninterface for models, embeddings, vector stores, and more.\\n\\nUse LangChain for: [...] ## LangChain’s ecosystem\\n\\nWhile the LangChain framework can be used standalone, it also integrates seamlessly\\nwith any LangChain product, giving developers a full suite of tools when building LLM\\napplications.\\n\\nTo improve your LLM application development, pair LangChain with:', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n",
      "=== Calling Function ===\n",
      "Calling function: Travily Search with args: {\"max_results\": 6, \"query\": \"LLM and LangChain\"}\n",
      "=== Function Output ===\n",
      "[Document(id_='022465e6-b9f5-40ce-8dd2-bd083fdaea80', embedding=None, metadata={'url': 'https://aws.amazon.com/what-is/langchain/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain is an open source framework for building applications based on large language models (LLMs). LLMs are large deep-learning models pre-trained on large amounts of data that can generate responses to user queries—for example, answering questions or creating images from text-based prompts. LangChain provides tools and abstractions to improve the customization, accuracy, and relevancy of the information the models generate. For example, developers can use LangChain components to build new [...] With LangChain, organizations can repurpose LLMs for domain-specific applications without retraining or fine-tuning. Development teams can build complex applications referencing proprietary information to augment model responses. For example, you can use LangChain to build applications that read data from stored internal documents and summarize them into conversational responses. You can create a Retrieval Augmented Generation (RAG) workflow that introduces new information to the language model [...] prompt chains or customize existing templates. LangChain also includes components that allow LLMs to access new data sets without retraining.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='ecfba0b0-0306-4860-8977-0120543e0511', embedding=None, metadata={'url': 'https://www.langchain.com/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# One interface, integrate any LLM.\\n\\nLangChain is the open, composable framework that provides a standard interface for every model, tool, and database â\\x80\\x93 so you can build LLM apps that adapt as fast as the ecosystem evolves.\\n\\n## Why use LangChain?\\n\\n## Composable by design\\n\\nLangChainâ\\x80\\x99s standard interface lets you experiment with different providers, tools, and databases â\\x80\\x93 creating DevEx parity when gaps exist.\\n\\n## Real-time data augmentation [...] LangChain is designed for connecting LLMs to data sources with minimal setup. LangGraph is our controllable agent orchestration framework, with out-of-the-box state management and human-in-the-loop capabilities. Use LangChain when you need fast integration and experimentation; use LangGraph when you need to build agents that can reliably handle complex tasks. [...] There are many different use cases for LangChain. Some common ones that we see include: chatbots and conversational interfaces, document Q&A and knowledge retrieval systems, and data extraction. LangChain excels when you need to connect LLMs to external data sources, APIs, or toolsâ\\x80\\x93 anywhere you need maximum integration flexibility.\\n\\nLangChain provides a standard interface for connecting models, tools, and data, then integrates seamlessly with any of the Lang- family products.Â\\n\\nâ\\x80\\x8d', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='fa528186-31fd-4e80-a11a-49411f67578a', embedding=None, metadata={'url': 'https://medium.com/@bijit211987/llm-powered-applications-building-with-langchain-cad4032d733c'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain provides an OpenAI Codex-based Python framework that makes working with LLMs simple and productive.\\n\\nWith LangChain you can:\\n\\nIt offers a clean Python API for leveraging LLMs without dealing with external APIs and infrastructure complexity.\\n\\nLangChain enables building a wide range of intelligent applications powered by LLMs including:\\n\\nThe remainder of this guide provides a deep dive into LangChain’s architecture and usage through concrete examples building LLM-enhanced applications. [...] By providing a code-first approach, LangChain opens the door to tightly integrating LLMs with custom logic and data flows tailored to specialized domains. As LLMs continue their rapid advancements, LangChain allows builders at any skill level to leverage these models for real-world impact.\\n\\n--\\n\\n--\\n\\nBijit Ghosh\\nBijit Ghosh\\n\\n## Written by Bijit Ghosh\\n\\nCTO | Senior Engineering Leader focused on Cloud Native | AI/ML | DevSecOps\\n\\n## No responses yet\\n\\nHelp\\n\\nStatus\\n\\nAbout\\n\\nCareers\\n\\nPress\\n\\nBlog [...] LangChain offers a robust framework for seamlessly leveraging large language models to build cutting-edge AI applications. In this blog post, we will use LangChain to add LLM-powered natural language generation, search, analytics, and automation to applications ranging from chatbots to semantic code search.\\n\\n# Introduction to Large Language Models', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='d5ae8dcb-f93b-4e7e-95c5-a14716995b5d', embedding=None, metadata={'url': 'https://www.ibm.com/think/topics/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# What is LangChain?\\n\\n## Authors\\n\\nSenior Writer, AI Models\\n\\nIBM\\n\\nEditorial Lead, AI Models\\n\\n## What is LangChain?\\n\\nLangChain is an open source orchestration framework for application development using large language models (LLMs). Available in both Python- and Javascript-based libraries, LangChain’s tools and APIs simplify the process of building LLM-driven applications like chatbots and AI agents. [...] LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows. LangChain’s module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code. This modular environment also allows for programs that use multiple LLMs: for example, an application that [...] ### Importing language models\\n\\nNearly any LLM can be used in LangChain. Importing language models into LangChain is easy, provided you have an API key. The LLM class is designed to provide a standard interface for all models.\\n\\nMost LLM providers will require you to create an account in order to receive an API key. Some of these APIs—particularly those for proprietary closed-source models, like those offered by OpenAI or Anthropic—may have associated costs.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='dcdb7b66-f810-4f19-b0cb-a834563df620', embedding=None, metadata={'url': 'https://python.langchain.com/docs/introduction/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='🦜️🔗 LangChain\\n🦜️🔗 LangChain\\nOpen on GitHub\\n\\n# Introduction\\n\\nLangChain is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDiagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.\\nDiagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='e7fe5098-22d6-4c5b-9e6d-580f4b4c7943', embedding=None, metadata={'url': 'https://github.com/langchain-ai/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain is a framework for building LLM-powered applications. It helps you chain\\ntogether interoperable components and third-party integrations to simplify AI\\napplication development — all while future-proofing decisions as the underlying\\ntechnology evolves.\\n\\n```\\npip install -U langchain\\n```\\n\\nTo learn more about LangChain, check out\\nthe docs. If you’re looking for more\\nadvanced customization or agent orchestration, check out\\nLangGraph, our framework for building\\ncontrollable agent workflows. [...] ## Why use LangChain?\\n\\nLangChain helps developers build applications powered by LLMs through a standard\\ninterface for models, embeddings, vector stores, and more.\\n\\nUse LangChain for: [...] ## LangChain’s ecosystem\\n\\nWhile the LangChain framework can be used standalone, it also integrates seamlessly\\nwith any LangChain product, giving developers a full suite of tools when building LLM\\napplications.\\n\\nTo improve your LLM application development, pair LangChain with:', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n",
      "=== LLM Response ===\n",
      "It seems like you've provided a list of documents related to LangChain and LLMs. LangChain is an open-source framework for building applications powered by large language models (LLMs). It provides a standard interface for models, embeddings, vector stores, and more, allowing developers to build LLM-powered applications with ease.\n",
      "\n",
      "LangChain can be used for various applications, such as chatbots, conversational interfaces, document Q&A, and knowledge retrieval systems. It also integrates seamlessly with other LangChain products, providing a full suite of tools for building LLM applications.\n",
      "\n",
      "Some of the key benefits of LangChain include:\n",
      "\n",
      "* Simplifying the development of LLM-powered applications\n",
      "* Providing a standard interface for models, embeddings, and vector stores\n",
      "* Allowing for easy integration with external data sources and software workflows\n",
      "* Enabling the use of multiple LLMs in a single application\n",
      "* Providing a modular environment for building and testing LLM applications\n",
      "\n",
      "Overall, LangChain is a powerful tool for developers looking to build applications powered by large language models.\n"
     ]
    }
   ],
   "source": [
    "agent = AgentRunner(agent_worker)\n",
    "response = agent.chat(\"me retorne artigos sobre llm e LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ee9c074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like you've provided a list of documents related to LangChain and LLMs. LangChain is an open-source framework for building applications powered by large language models (LLMs). It provides a standard interface for models, embeddings, vector stores, and more, allowing developers to build LLM-powered applications with ease.\n",
      "\n",
      "LangChain can be used for various applications, such as chatbots, conversational interfaces, document Q&A, and knowledge retrieval systems. It also integrates seamlessly with other LangChain products, providing a full suite of tools for building LLM applications.\n",
      "\n",
      "Some of the key benefits of LangChain include:\n",
      "\n",
      "* Simplifying the development of LLM-powered applications\n",
      "* Providing a standard interface for models, embeddings, and vector stores\n",
      "* Allowing for easy integration with external data sources and software workflows\n",
      "* Enabling the use of multiple LLMs in a single application\n",
      "* Providing a modular environment for building and testing LLM applications\n",
      "\n",
      "Overall, LangChain is a powerful tool for developers looking to build applications powered by large language models.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "febf0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91e9dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 160 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "url = \"files/LLM.pdf\"\n",
    "artigo= SimpleDirectoryReader(input_files=[url]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c719163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"files/LLM_2.pdf\"\n",
    "tutorial= SimpleDirectoryReader(input_files=[url]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f993c",
   "metadata": {},
   "source": [
    "###Gerar os Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06e4ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "035ce058",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"intfloat/multilingual-e5-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0883a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_index= VectorStoreIndex.from_documents(artigo)\n",
    "tutorial_index = VectorStoreIndex.from_documents(tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e95d36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_index.storage_context.persist(persist_dir=\"artigo\")\n",
    "tutorial_index.storage_context.persist(persist_dir=\"tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92545289",
   "metadata": {},
   "source": [
    "###Engine de Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2d23c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6c3d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from artigo\\docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from artigo\\index_store.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from tutorial\\docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from tutorial\\index_store.json.\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"artigo\"\n",
    ")\n",
    "\n",
    "artigo_index = load_index_from_storage(storage_context)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"tutorial\"\n",
    ")\n",
    "\n",
    "tutorial_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4565ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_engine = artigo_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "tutorial_engine = tutorial_index.as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d02d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10e64b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=artigo_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"artigo_engine\",\n",
    "            description=(\n",
    "                \"fornece informações sobre llm e langChain\"\n",
    "                \"Use um apergunta detalhada e texto simples como entrada pra ferramenta\"\n",
    "            )\n",
    "        )\n",
    "    ), \n",
    "\n",
    "QueryEngineTool(\n",
    "        query_engine=tutorial_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"tutorial_engine\",\n",
    "            description=(\n",
    "                \"fornece informações sobre casos de uso e aplicações de llm\"\n",
    "                \"Use um apergunta detalhada e texto simples como entrada pra ferramenta\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "175ea82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_11324\\1421250311.py:8: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  agent_document = AgentRunner(agent_worker)\n"
     ]
    }
   ],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    query_engine_tools,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "agent_document = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e89bdfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: quais as principais aplicações posso costruir com llm e langchain?\n",
      "=== Calling Function ===\n",
      "Calling function: artigo_engine with args: {\"input\": \"quais as principais aplica\\u00e7\\u00f5es posso costruir com llm e langchain?\"}\n",
      "=== Function Output ===\n",
      "Based on the provided context, some of the main applications you can build with LLMs include chatbots and virtual assistants, code generation and debugging, sentiment analysis, text classification and clustering, language translation, summary and paraphrasing, and content generation.\n",
      "=== LLM Response ===\n",
      "Based on the provided context, some of the main applications you can build with LLMs include chatbots and virtual assistants, code generation and debugging, sentiment analysis, text classification and clustering, language translation, summary and paraphrasing, and content generation.\n"
     ]
    }
   ],
   "source": [
    "response = agent_document.chat(\n",
    "    \"quais as principais aplicações posso costruir com llm e langchain?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "effcf89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, some of the main applications you can build with LLMs include chatbots and virtual assistants, code generation and debugging, sentiment analysis, text classification and clustering, language translation, summary and paraphrasing, and content generation.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a0594",
   "metadata": {},
   "source": [
    "###Agente ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c202d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d497d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programacao\\automacao\\Llama\\.venv\\Lib\\site-packages\\llama_index\\core\\agent\\react\\base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
      "\n",
      "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
      "\n",
      "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return cls(\n",
      "c:\\programacao\\automacao\\Llama\\.venv\\Lib\\site-packages\\deprecated\\classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return old_new1(cls, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "agente = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86247dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: quais as principais ferramentas usadas em LangChain\n",
      "=== Calling Function ===\n",
      "Calling function: Travily Search with args: {\"max_results\": 6, \"query\": \"LangChain\"}\n",
      "=== Function Output ===\n",
      "[Document(id_='a6b8c3f1-0a1f-465b-8dd0-63591f0829f1', embedding=None, metadata={'url': 'https://en.wikipedia.org/wiki/LangChain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Image 5Free and open-source software portal\\n\\nLangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.(\\n\\nHistory\\n-------\\n\\n[edit] [...] LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. The project quickly garnered popularity,( with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a [...] | LangChain |\\n| --- |\\n| Image 4: 🦜️🔗, the parrot and chain emojis |\\n| Developer(s) | Harrison Chase |\\n| Initial release | October 2022 |\\n|  |\\n| Stable release | 0.1.16( / 11 April 2024; 14 months ago(11 April 2024) |\\n|  |\\n| Repository \"Repository (version control)\") | github.com/langchain-ai/langchain |\\n| Written in | Python \"Python (programming language)\") and JavaScript |\\n| Type | Software framework for large language model application development |\\n| License | MIT License |', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='8d948f8d-6799-44c4-8026-35895060c191', embedding=None, metadata={'url': 'https://www.ibm.com/think/topics/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain is an open source orchestration framework for application development using large language models (LLMs). Available in both Python- and Javascript-based libraries, LangChain’s tools and APIs simplify the process of building LLM-driven applications like chatbots and AI agents. [...] LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models. These modular components—like functions and object classes—serve as the building blocks of generative AI programs. They can be “_chained_” together to create applications, minimizing the amount of code and fine understanding required to execute complex NLP tasks. Though LangChain’s abstracted approach may limit the extent to which an expert [...] LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows. LangChain’s module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code. This modular environment also allows for programs that use multiple LLMs: for example, an application that', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='e92ba12c-2980-4718-98c1-92447c28aef9', embedding=None, metadata={'url': 'https://www.techtarget.com/searchenterpriseai/definition/LangChain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain is an open source framework that enables software developers working with artificial intelligence (AI) and its machine learning subset to combine large language models with other external components to develop LLM\\\\-powered applications. [...] LangChain is a framework that simplifies the process of creating generative AI application interfaces. Developers working on these types of interfaces use various tools to create advanced NLP apps; LangChain streamlines this process. For example, LLMs must access large volumes of big data, so LangChain organizes these large quantities of data so that they can be accessed with ease.\\n\\nThis article is part of\\n\\n### What is GenAI? Generative AI explained [...] Interactive applications. LangChain enables interactive applications through real-time communication with language models. For example, its modular components can be used to create interactive applications such as chatbots and AI assistants that engage users in real time.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='183431db-2a2c-4be0-bff7-993625797041', embedding=None, metadata={'url': 'https://github.com/langchain-ai/langchain'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain is a framework for building LLM-powered applications. It helps you chain\\ntogether interoperable components and third-party integrations to simplify AI\\napplication development — all while future-proofing decisions as the underlying\\ntechnology evolves.\\n\\n```\\npip install -U langchain\\n```\\n\\nTo learn more about LangChain, check out\\nthe docs. If you’re looking for more\\nadvanced customization or agent orchestration, check out\\nLangGraph, our framework for building\\ncontrollable agent workflows. [...] ## Why use LangChain?\\n\\nLangChain helps developers build applications powered by LLMs through a standard\\ninterface for models, embeddings, vector stores, and more.\\n\\nUse LangChain for: [...] - Real-time data augmentation. Easily connect LLMs to diverse data sources and\\n  external / internal systems, drawing from LangChain’s vast library of integrations with\\n  model providers, tools, vector stores, retrievers, and more.\\n- Model interoperability. Swap models in and out as your engineering team\\n  experiments to find the best choice for your application’s needs. As the industry\\n  frontier evolves, adapt quickly — LangChain’s abstractions keep you moving without\\n  losing momentum.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='f4618221-a470-4ea1-94c8-2f2cd3aebc27', embedding=None, metadata={'url': 'https://python.langchain.com/docs/introduction/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Image 3: Diagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the integrations page for more.\\n\\nSelect chat model:\\n\\nGoogle Gemini▾ [...] Architecture\\u200b\\n-----------------------------------------------------------------------------------------------------------\\n\\nThe LangChain framework consists of multiple open-source libraries. Read more in the Architecture page. [...] `langchain-core`: Base abstractions for chat models and other components.\\n   Integration packages (e.g. `langchain-openai`, `langchain-anthropic`, etc.): Important integrations have been split into lightweight packages that are co-maintained by the LangChain team and the integration developers.\\n   `langchain`: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.\\n   `langchain-community`: Third-party integrations that are community maintained.\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='2cbf2734-9634-459f-94c0-4c4108905368', embedding=None, metadata={'url': 'https://medium.com/@bijit211987/llm-powered-applications-building-with-langchain-cad4032d733c'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='To maximize cache reuse across instances, LangChain offers distributed caching powered by Redis.\\n\\nThis shares cache entries between processes and servers:\\n\\nEnable distributed caching like:\\n\\nai = OpenAI(cache=RedisCache(redis\\\\_client))\\n\\nNow multiple app servers can lookup cached results in the shared Redis store.\\n\\nBenefits include:\\n\\n   Eliminate duplicate model queries\\n   Share caches globally across regions\\n   Scale to millions of cache entries\\n   Cache lookups remain fast [...] The examples only scratch the surface of what is possible by combining application code with the reasoning capabilities of LLMs using LangChain.\\n\\nBy providing a code-first approach, LangChain opens the door to tightly integrating LLMs with custom logic and data flows tailored to specialized domains. As LLMs continue their rapid advancements, LangChain allows builders at any skill level to leverage these models for real-world impact.\\n\\nImage 4 [...] Automated song writing\\n   Interactive fiction and text adventure games\\n   ML-assisted coding and content creation\\n   Developing premises, characters, and plots for books/films\\n\\nCreativity-enhancing tools provide limitless possibilities for artistic expression using LLMs.\\n\\nChaining Multiple Models\\n========================\\n\\nA key capability of LangChain is its ability to chain different language models together into a pipeline.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n",
      "=== LLM Response ===\n",
      "As per the tool call result, the main tools used in LangChain are:\n",
      "\n",
      "1. Large Language Models (LLMs): LangChain is a framework that helps facilitate the integration of LLMs into applications.\n",
      "\n",
      "2. Embedding models and vector stores: LangChain implements a standard interface for these technologies and integrates with hundreds of providers.\n",
      "\n",
      "3. Chat models: LangChain provides a standard interface for chat models and other components.\n",
      "\n",
      "4. Retrieval strategies: LangChain includes chains, agents, and retrieval strategies that make up an application's cognitive architecture.\n",
      "\n",
      "5. Integration packages: LangChain has integration packages (e.g., `langchain-openai`, `langchain-anthropic`, etc.) that are co-maintained by the LangChain team and the integration developers.\n",
      "\n",
      "6. Distributed caching powered by Redis: LangChain offers distributed caching to share cache entries between processes and servers.\n",
      "\n",
      "These tools are used to build LLM-powered applications, including chatbots, AI assistants, and other interactive applications.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"quais as principais ferramentas usadas em LangChain\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
