{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47685ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.conversation.base import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c386f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_4716\\1496525348.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory= ConversationBufferMemory()\n",
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_4716\\1496525348.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  chain = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "memory= ConversationBufferMemory()\n",
    "chain = ConversationChain(\n",
    "    llm = chat,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23922feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá! Como posso ajudá-lo hoje?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"Olá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e53630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_4716\\3702201645.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"Olá\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá\n",
      "AI: Olá! Como posso ajudá-lo hoje?\n",
      "Human: Olá\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Olá de novo! Como posso ajudá-lo desta vez?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Olá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f05028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"Essa é uma conversa amigavel entre um humano e uma IA\n",
    "\n",
    "    Conversa atual: \n",
    "    {history}\n",
    "    Human: {input}\n",
    "    AI:                                                                   \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24782582",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "memory= ConversationBufferMemory()\n",
    "chain = ConversationChain(\n",
    "    prompt = prompt_template,\n",
    "    llm = chat,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7706a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEssa é uma conversa amigavel entre um humano e uma IA\n",
      "\n",
      "    Conversa atual: \n",
      "    Human: Oi\n",
      "AI: Olá! Como posso te ajudar hoje?\n",
      "Human: Oi\n",
      "AI: Olá! Como posso te ajudar hoje?\n",
      "Human: Meu nome é arthur\n",
      "AI: Olá, Arthur! É um prazer conhecê-lo. Como posso ajudá-lo hoje?\n",
      "    Human: Meu nome é arthur\n",
      "    AI:                                                                   \n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Arthur! Como posso te ajudar hoje?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Meu nome é arthur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefe7df",
   "metadata": {},
   "source": [
    "### LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1d6ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a352d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_4716\\3754699681.py:7: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=chat, prompt = prompt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LangChain Solutions'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Escolha o melhor nome par amim sobre uma empresa que desenvolve soluções em {produto}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt = prompt)\n",
    "produto = \"LLM com LangChain\"\n",
    "chain.run(produto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123304e",
   "metadata": {},
   "source": [
    "### Simple Sequence Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ce33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2b76430",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Escolha o melhor nome par amim sobre uma empresa que desenvolve soluções em {produto}\n",
    "    \"\"\"\n",
    ")\n",
    "chain_nome = LLMChain(llm=chat, prompt = prompt)\n",
    "\n",
    "prompt_descricao = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Sobre a empresa com o nome {nome_empresa}, informe uma descrição de até 20 palavras\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_descricao = LLMChain(llm = chat, prompt=prompt_descricao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93744fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mLangChain Solutions LLM Co.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mA LangChain Solutions LLM Co. é uma empresa especializada em serviços de consultoria e soluções em linguagem corporativa.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A LangChain Solutions LLM Co. é uma empresa especializada em serviços de consultoria e soluções em linguagem corporativa.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = SimpleSequentialChain(\n",
    "    chains = [chain_nome, chain_descricao],\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "chain.run(produto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
