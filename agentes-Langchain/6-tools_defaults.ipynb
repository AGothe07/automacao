{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0075533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "tool_repl = PythonREPLTool()\n",
    "tool_repl.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d27818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The Zen of Python, by Tim Peters\\n\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nFlat is better than nested.\\nSparse is better than dense.\\nReadability counts.\\nSpecial cases aren't special enough to break the rules.\\nAlthough practicality beats purity.\\nErrors should never pass silently.\\nUnless explicitly silenced.\\nIn the face of ambiguity, refuse the temptation to guess.\\nThere should be one-- and preferably only one --obvious way to do it.\\nAlthough that way may not be obvious at first unless you're Dutch.\\nNow is better than never.\\nAlthough never is often better than *right* now.\\nIf the implementation is hard to explain, it's a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\nNamespaces are one honking great idea -- let's do more of those!\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_repl.run({\"query\":\"import this\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc27e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools([\"stackexchange\"])\n",
    "\n",
    "tool_stack = tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed96a0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: GPT-OSS does not return valid structured output with Langchain\\nI&#39;m using <span class=\"highlight\">LangChain</span> with GPT-OSS models (served via Hyperbolic) to generate and evaluate answers. &hellip; \\n\\nQuestion: How to ensure all documents contribute to summary context after merging indexes?\\nI&#39;m building a <span class=\"highlight\">LangChain</span> RAG pipeline using the FAISS vector store. &hellip; \\nAnswer: You can use Ensemble Retrievers. So the idea here is to even the chances of fetching documents/chunks in the retrievers. What you are doing here is combining all the vectorized data together, so when  … \\n\\nQuestion: Llama 2 with Langchain tools\\nI am trying to follow this tutorial on using Llama 2 with <span class=\"highlight\">Langchain</span> tools (you don&#39;t have to look at the tutorial all code is contained in this question). &hellip; I am using Python 3.11.5 with Anaconda, tensorflow 2.15.0, transformers 4.35.2, <span class=\"highlight\">langchain</span> 0.0.336, on macOS Sonoma. &hellip; \\nAnswer: I found that it works with Llama 2 70b, but not with Llama 2 13b. Llama 2 13b uses the tool correctly and observes the final answer which is in its agent_scratchpad, but it outputs an empty string at  … '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_stack.run({\"query\":\"LangChain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c3541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
